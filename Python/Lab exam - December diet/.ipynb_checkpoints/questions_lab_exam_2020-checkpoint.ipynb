{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab exam 2020\n",
    "\n",
    "## Rules\n",
    "\n",
    "* **Read the rules carefully before you begin.**\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "* This submission must be 100% your own work. Do not discuss, share or collaborate on any part of this exam with any other person. \n",
    "    \n",
    "</div>\n",
    "\n",
    "* This is an **open book** exam. You **may** consult external references (books, Stack Overflow, etc.) but you **must not** copy and paste code verbatim; nor may you reveal or discuss any aspect of the exam with anyone in an online (or offline) medium.\n",
    "* You must submit the correct file on Moodle by the posted deadline. There are no extensions.\n",
    "* You may not import *any* libraries beyond those already imported for you. You do not need to use a library just because it is imported!\n",
    "\n",
    "---\n",
    "\n",
    "### Marking\n",
    "* This exam is marked out of 80.\n",
    "* The division of marks is listed by each task.\n",
    "* The three parts of this exam are *independent*. If you cannot complete one, this will not affect your ability to complete the others.\n",
    "* The parts increase in difficulty. Remember: partial solutions will get credit. You do not have to have completely working code, or implement all of the features requested, to get most of the marks. Make an attempt if you can.\n",
    "* You are warned that spending excess time will not likely increase your grade but will increase your stress levels. \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important\n",
    "Please enter, into the cell marked **[STATEMENT BELOW]** below, the following statement:\n",
    "\n",
    "> I, [your name], have read and understand the rules governing this lab exam and I will abide by them.\n",
    "    \n",
    "(double-click a cell to edit it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I, Iliyan Kalphov, have read and understand the rules governing this lab exam and I will abide by them.\n",
    "[STATEMENT HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T09:50:50.512459Z",
     "start_time": "2020-11-26T09:50:50.508556Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math, random, functools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "A **word search puzzle** is a square grid of letters, where some sequences of letters make up words, and the rest are random letters. The puzzle is to find a list of known words in the grid. Words may be written horizontally, and sometimes vertically or even diagonally. In some variations, words can be reversed. \n",
    "\n",
    "The puzzle below contains the words `block`, `spain`, `sugar`, `beans`:\n",
    "\n",
    "        S V B S B\n",
    "        P Q L U E\n",
    "        A I O G A\n",
    "        I C C A N\n",
    "        N W K R S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading words\n",
    "\n",
    "You are building a system to help design word search puzzles. To do this, you have been asked to process some dictionary data to produce suitable word sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Read in words\n",
    "\n",
    "Write a function `read_lines(fname)`. This should read a file named `fname` and return a list of lines, which should be stripped of newlines. There are 32 lines in the file `test.txt` and 19438 lines in the file `dictionary.txt`, and 0 lines in `empty.txt`. Write tests to make sure this function works. \n",
    "\n",
    "**[5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T09:50:53.239732Z",
     "start_time": "2020-11-26T09:50:53.226068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Solution goes here\n",
    "def read_lines(fname):\n",
    "    with open(fname) as file:\n",
    "        list_of_lines = [line.strip('\\n') for line in file]\n",
    "    return list_of_lines\n",
    "\n",
    "assert read_lines(\"empty.txt\") == []\n",
    "assert len(read_lines(\"test.txt\")) == 32\n",
    "assert len(read_lines(\"dictionary.txt\")) == 19438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Clean up\n",
    "You want to read the file `dictionary.txt` using the function above. \n",
    "\n",
    "Unfortunately, the dictionary has been transcribed poorly. Each line has several words in it, separated by one or more spaces. The case of letters is sometimes upper or lower case.  The words are in random order. Occasionally a page number appears mixed in with the words, which must be ignored. Words never contain line numbers; they are always separated by a space.\n",
    "\n",
    "For example, part of `dictionary.txt` reads:\n",
    "\n",
    "    Jags dunks\n",
    "    uncoated CHAUFFEUSE drudgery\n",
    "    249 ACCELERATIONS\n",
    "    alabama\n",
    "    Mellows sealed\n",
    "    \n",
    "The 249 is a page number and should be ignored. Valid words for our purposes only consist of alphabetic letters. These would be, in this case,\n",
    "\n",
    "    jags\n",
    "    dunks\n",
    "    uncoated\n",
    "    chauffeuse\n",
    "    drudgery\n",
    "    accelerations\n",
    "    alabama\n",
    "    mellows\n",
    "    sealed\n",
    "    \n",
    "Any contractions or hyphenated words, like `don't` or `can't` or `topsy-turvy` should *also* be removed, as they have non-alphabetic characters.\n",
    "  \n",
    "* Write a function `clean_line(line)` that will take *one* line and return the valid words in it, all lowercase, **as a list**.\n",
    "* Write tests to make sure `clean_line(line)` works correctly.\n",
    "* Write a function `clean_all_lines(lines)` that will take a list like the return value of `read_lines` and return a list of words, cleaned by `clean_line` and **sorted into alphabetic order.**\n",
    "* Write tests to make sure `clean_all_lines` works correctly.\n",
    "* The words in `dictionary_txt` begin \"a\" and end \"zwolle\". There are 65152 words. \n",
    "\n",
    "**[12 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:48:37.296074Z",
     "start_time": "2020-11-28T10:48:37.226274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Solution goes here\n",
    "def clean_line(line):\n",
    "    return [word.lower() for word in line.split() if word.isalpha()]\n",
    "\n",
    "assert clean_line(\"\")==[]\n",
    "assert clean_line(\"ABC abC\") == [\"abc\",\"abc\"]\n",
    "assert clean_line(\"123 abC\") == [\"abc\"]\n",
    "assert clean_line(\"123 ABc don't 32\") == [\"abc\"]\n",
    "assert clean_line(\"aBc topsy-turvy\") == [\"abc\"]\n",
    "assert clean_line(\"abc   sqrt 12\") == [\"abc\",\"sqrt\"]\n",
    "\n",
    "def clean_all_lines(lines):\n",
    "    word_list = []\n",
    "    for line in lines:\n",
    "        word_list.extend(clean_line(line))\n",
    "    word_list.sort()\n",
    "    return word_list\n",
    "\n",
    "dictionary = read_lines(\"dictionary.txt\")\n",
    "assert len(clean_all_lines(dictionary))==65152\n",
    "assert clean_all_lines(dictionary)[0] == \"a\"\n",
    "assert clean_all_lines(dictionary)[len(clean_all_lines(dictionary)) - 1] == \"zwolle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Choose good words\n",
    "Dictionary words aren't all good choices for a word search. \n",
    "\n",
    "The file `common_words.txt` has the 1000 most common words in English in it, one word per line. \n",
    "\n",
    "* Use the functions you defined above to read this file. All words are 1 to 13 characters long.\n",
    "* Write tests to validate you have read it correctly.\n",
    "\n",
    "#### Filtering the good words\n",
    "* Write a function `good_words(dictionary, common_words)` that will take the dictionary words from `clean_all_lines()` and the common words you just loaded, and apply all of the following rules to select words from the dictionary that are good for a word search. Return the \"good\" words as a list, sorted in order of word length, shortest word first. A word is good if it:\n",
    "    * is not a common word;\n",
    "    * is three to eight characters long;\n",
    "    * has at least one vowel;\n",
    "    * is not equal to itself reversed (e.g. `naan` reversed is `naan` and would be excluded);\n",
    "    * if two words in the dictionary are the same *except* one has an `s` at the end, the word without the `s` should be kept, and the other discarded. For examples, \"cats\" and \"cat\" should become just \"cat\"; \"burger\" and \"burgers\" should become \"burger\".\n",
    "* Write tests to check `good_words` works OK  \n",
    "\n",
    "For the last two marks, make your solution *reasonably* efficient -- in particular, it should avoid executing in O(N^2) time, where N is the number of words in the dictionary. As a very rough guide, an efficient implementation might take 100-2000ms running the timing test on most machines, but not *much* more.\n",
    "\n",
    "There are around 20000-40000 good words. `yourself`, `zucchini`, `galaxies`, `ant`, `ape`, `ark` are all \"good words\".\n",
    "\n",
    "**[20 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T12:32:01.116459Z",
     "start_time": "2020-11-26T12:32:01.051067Z"
    }
   },
   "outputs": [],
   "source": [
    "# Solution goes here\n",
    "common_words = read_lines(\"common_words.txt\")\n",
    "\n",
    "#common_words assertions\n",
    "assert len(common_words) == 1000\n",
    "for word in common_words:\n",
    "    assert len(word)>=1 and len(word)<=13\n",
    "\n",
    "def good_words(dictionary_words, common_words):\n",
    "    dictionary = {}\n",
    "    l = []\n",
    "    for word in dictionary_words:\n",
    "        if not word in common_words:\n",
    "            dictionary[word] = True\n",
    "    for word in dictionary:\n",
    "        flag = True\n",
    "        if len(word)<3 or len(word)>8:\n",
    "            flag = False\n",
    "        if len([ch for ch in word if ch in \"aeiou\"])==0:\n",
    "            flag = False\n",
    "        if word == word[::-1]:\n",
    "            flag = False\n",
    "        if word.endswith('s'):\n",
    "            if word[:len(word)-1] in dictionary:\n",
    "                flag = False\n",
    "        if flag:\n",
    "            l.append(word)\n",
    "    return sorted(l,key = lambda x: len(x))\n",
    "    \n",
    "#good_words asserstions\n",
    "assert good_words([\"cat\",\"the\",\"turtle\",\"from\"], common_words) == [\"cat\",\"turtle\"]\n",
    "assert good_words([\"cat\",\"postcodes\"], common_words) == [\"cat\"]\n",
    "assert good_words([\"psst\",\"krr\",\"turtle\"], common_words) == [\"turtle\"]\n",
    "assert good_words([\"prosecution\",\"shovel\",\"bob\"], common_words) == [\"shovel\"]\n",
    "assert good_words([\"cat\",\"cats\",\"dog\",\"dogs\"], common_words) == [\"cat\",\"dog\"]\n",
    "\n",
    "dictionary = clean_all_lines(read_lines(\"dictionary.txt\"))\n",
    "\n",
    "assert len(good_words(dictionary, common_words)) >=20_000 and len(good_words(dictionary, common_words)) <=40_000\n",
    "for word in [\"yourself\",\"zucchini\",\"galaxies\",\"ant\",\"ape\",\"ark\"]:\n",
    "    assert word in good_words(dictionary, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T08:10:14.592022Z",
     "start_time": "2020-11-27T08:10:13.051543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15 s ± 9.04 ms per loop (mean ± std. dev. of 2 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 2\n",
    "## Timing test\n",
    "good_words(dictionary, common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: A word search finder\n",
    "\n",
    "Word search puzzles use random letters to hide the letter patterns.\n",
    "\n",
    "For example: find the words \"spleen, matrix, coding, lambda, basil\" in the 8x8 grid below:\n",
    "\n",
    "    G S P L E E N D\n",
    "    S P G H C F R M\n",
    "    T P Z L O C A B\n",
    "    I L D Z D V J A\n",
    "    M A T R I X B S\n",
    "    A J C G N X D I\n",
    "    A A B S G R Z L\n",
    "    V L A M B D A L\n",
    "    \n",
    "The solution can be seen in the lower case characters below:\n",
    "\n",
    "    G s p l e e n D\n",
    "    S P G H c F R M\n",
    "    T P Z L o C A b\n",
    "    I L D Z d V J a\n",
    "    m a t r i x B s\n",
    "    A J C G n X D i\n",
    "    A A B S g R Z l\n",
    "    V l a m b d a L\n",
    "    \n",
    "### Find words\n",
    "Write a function `find_words(puzzle, words)` that takes a word search puzzle as a string, and a list of potential words, and returns each of the words found in the puzzle in a list. This should find words hidden horizontally (left-to-right) or vertically (top-to-bottom). The search should ignore case, and always return the found words in lower case. It should only ever return a detected word at most *once*. It should ignore any blank lines.\n",
    "\n",
    "Note: if you choose to only detect horizontal words, you will lose five of the possible marks.\n",
    "\n",
    "[**18 marks**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T12:56:25.929803Z",
     "start_time": "2020-11-26T12:56:25.923948Z"
    }
   },
   "outputs": [],
   "source": [
    "# Solution goes here\n",
    "def find_words(puzzle, words):\n",
    "    puzzle_rows = puzzle.strip().lower().split(\"\\n\")\n",
    "    array = np.array([row.split(\" \") for row in puzzle_rows])\n",
    "    new_l = []\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        for row in array:\n",
    "            row_string = \"\".join(row)\n",
    "            if not word in new_l: \n",
    "                if word in row_string:\n",
    "                    new_l.append(word)\n",
    "        for column in range(array.shape[1]):\n",
    "            column_string = \"\".join(array[:,column])\n",
    "            if not word in new_l: \n",
    "                if word in column_string:\n",
    "                    new_l.append(word)\n",
    "    return new_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T12:15:03.943118Z",
     "start_time": "2020-11-26T12:15:03.933357Z"
    }
   },
   "outputs": [],
   "source": [
    "## Tests\n",
    "\n",
    "search = \"\"\"\n",
    "G S P L E E N D\n",
    "S P G H C F R M\n",
    "T P Z L O C A B\n",
    "I L D Z D V J A\n",
    "M A T R I X B S\n",
    "A J C G N X D I\n",
    "A A B S G R Z L\n",
    "V L A M B D A L\n",
    "\"\"\"\n",
    "\n",
    "# compare two lists, ignoring order\n",
    "def unordered_test(a,b):\n",
    "    return sorted(a) == sorted(b)\n",
    "\n",
    "assert unordered_test(find_words(search, [\"lada\", \"bail\"]), [])\n",
    "assert unordered_test(find_words(search, []),[])\n",
    "assert unordered_test(find_words(search, [\"sbs\"]),[])\n",
    "assert unordered_test(find_words(search, [\"matrix\"]), [\"matrix\"])\n",
    "assert unordered_test(find_words(search, [\"lambda\", \"basil\"]),[\"lambda\", \"basil\"])\n",
    "assert unordered_test(find_words(search, [\"LAMBDA\", \"basil\"]),[\"lambda\", \"basil\"])\n",
    "assert unordered_test(find_words(search, [\"lAmbda\", \"BaSiL\"]),[\"lambda\", \"basil\"])\n",
    "    \n",
    "search_2 = \"\"\"\n",
    "F B S B s\n",
    "G L P E u\n",
    "B O A A g\n",
    "P C I N a\n",
    "O K N S r\n",
    "\"\"\"\n",
    "\n",
    "assert unordered_test(find_words(search_2, [\"lada\", \"bail\"]),[])\n",
    "assert unordered_test(find_words(search_2, [\"spain\", \"bail\"]),[\"spain\"])\n",
    "assert unordered_test(find_words(search_2, [\"spain\", \"sugar\"]),[\"spain\", \"sugar\"])\n",
    "assert unordered_test(find_words(search_2, [\"spainish\"]),[])\n",
    "\n",
    "search_3 = \"\"\"\n",
    "B S B S S S\n",
    "E P E U U P\n",
    "A A A G G A\n",
    "N I N A A I\n",
    "S N S R R N\n",
    "S U G A R R\n",
    "\"\"\"\n",
    "\n",
    "assert unordered_test(find_words(search_3, [\"lada\", \"bail\"]),[])\n",
    "assert unordered_test(find_words(search_3, [\"spain\"]),[\"spain\"])\n",
    "assert unordered_test(find_words(search_3, [\"spain\", \"beans\", \"sugar\"]),[\"spain\", \"beans\", \"sugar\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt for reversed words\n",
    "\n",
    "Adapt your solution to re-define a new version of `find_words(puzzle, words)` that also detects **reversed** words (both horizontal and vertical). For example\n",
    "\n",
    "    M P F A O\n",
    "    A I R J L\n",
    "    P E O A L\n",
    "    S C M M E\n",
    "    Z E P Z H\n",
    "\n",
    "\n",
    "contains \"hello\", but written bottom-to-top, and \"pez\" written right-to-left, as well as \"jam\" written top-to-bottom and \"air\" written left-to-right. The return value \n",
    "of `find_word(search, [\"hello\", \"pez\", \"jam\", \"air\"])` should be `[\"hello\", \"pez\", \"jam\", \"air\"]` (in any order).\n",
    "\n",
    "[**5 marks**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T12:15:51.365811Z",
     "start_time": "2020-11-26T12:15:51.359956Z"
    }
   },
   "outputs": [],
   "source": [
    "# Solution goes here\n",
    "def find_words(puzzle, words):\n",
    "    puzzle_rows = puzzle.strip().lower().split(\"\\n\")\n",
    "    array = np.array([row.split(\" \") for row in puzzle_rows])\n",
    "    new_l = []\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        for row in array:\n",
    "            row_string = \"\".join(row)\n",
    "            if word in row_string or word in row_string[::-1]:\n",
    "                if not word in new_l: \n",
    "                    new_l.append(word)\n",
    "        for column in range(array.shape[1]):\n",
    "            column_string = \"\".join(array[:,column])\n",
    "            if word in column_string or word in column_string[::-1]:\n",
    "                if not word in new_l: \n",
    "                    new_l.append(word)\n",
    "    return new_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T12:15:41.421982Z",
     "start_time": "2020-11-26T12:15:41.416127Z"
    }
   },
   "outputs": [],
   "source": [
    "search_4 = \"\"\"\n",
    "M P F A O\n",
    "A I R J L\n",
    "P E O A L\n",
    "S C M M E\n",
    "Z E P Z H\n",
    "\"\"\"\n",
    "\n",
    "assert find_words(search_4, [])==[]\n",
    "assert find_words(search_4, [\"lada\", \"bail\"])==[]\n",
    "assert find_words(search_4, [\"spain\", \"bail\"])==[]\n",
    "assert find_words(search_4, [\"hello\"]) == [\"hello\"]\n",
    "assert unordered_test(find_words(search_4, [\"hello\", \"spam\", \"from\", \"me\", \"cats\"]), [\"hello\", \"spam\", \"from\", \"me\"])\n",
    "assert unordered_test(find_words(search_4, [\"hello\", \"jam\", \"air\", \"pez\"]), [\"hello\", \"jam\", \"air\", \"pez\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Generating a word search\n",
    "\n",
    "Write a function `generate_word_search(n, words, horizontal=True, vertical=False, reversed=False)` that will generate a word search of size `n x n` containing all the words in `words` and return it as a string, one row per line. **If it is impossible to fit the words in the grid because they are too long, an error should occur.**\n",
    "\n",
    "You do not need to consider the case where there are too many words to fit into a word search. You do not have to deal with overlapping words, but you must make sure that every word in `words` appears correctly in the final puzzle.\n",
    "\n",
    "Each parameter `horizontal`, `vertical` should enable or disable embedding words in that orientation -- **at least one of these must be True, or an error should occur**; `reversed` will allow reversed words in all enabled orientations. If multiple directions are enabled, the direction of each word should be set randomly.\n",
    "\n",
    "Every entry in the output word search should be an upper case letter. Passing an input word with a non-letter **should cause an error**.\n",
    "\n",
    "Note:\n",
    "\n",
    "* `random.choice(l)` chooses a random element of a list `l`\n",
    "* `random.randint(0, n)` chooses a random number between 0 and (including) `n`\n",
    "\n",
    "Note: the easiest (but not only) way to approach this is to initialise a grid of random letters and make *random attempts* to place words in it.\n",
    "\n",
    "\n",
    "\n",
    "Every letter in a row in the returned string should be separated by spaces, as in the examples.\n",
    "\n",
    "For example, \n",
    "\n",
    "    grid = generate_word_search(5, [\"hello\", \"from\", \"me\"])   \n",
    "\n",
    "might produce:\n",
    "\n",
    "    N I U R I\n",
    "    Y X F J I\n",
    "    H E L L O\n",
    "    F R O M A\n",
    "    H I M E Z\n",
    "    \n",
    "(note that the \"background\" letters are chosen *randomly*)\n",
    "    \n",
    "and\n",
    "    \n",
    "    grid = generate_word_search(8, [\"hello\", \"from\", \"my\", \"secret\", \"lair\"], horizontal=True, vertical=True)   \n",
    "    \n",
    "might produce:\n",
    "\n",
    "    S C D D L G C R\n",
    "    E E F H A M J J\n",
    "    C T Q E I H F Q\n",
    "    R K Y L R H E A\n",
    "    E W C L T H H X\n",
    "    T D A O A S K G\n",
    "    Q P F R O M E P\n",
    "    M Y L Y K C R G\n",
    "    \n",
    "while \n",
    "\n",
    "    grid = generate_word_search(4, [\"hello\", \"from\", \"my\", \"secret\", \"lair\"], horizontal=True, vertical=True)   \n",
    "    \n",
    "would produce an error (`secret` is more than 4 characters long), as would:\n",
    "\n",
    "    grid = generate_word_search(5, [\"hello\", \"from\", \"CS1P\"])   \n",
    "\n",
    "(as 1 is not a letter).\n",
    "\n",
    "\n",
    "**[20 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T11:55:12.734023Z",
     "start_time": "2020-11-26T11:55:12.718876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U R T O I G\n",
      "X C V Z M Q\n",
      "B A S I L Z\n",
      "M A T R I X\n",
      "L D I W W N\n",
      "S P L E E N\n"
     ]
    }
   ],
   "source": [
    "# Solution goes here\n",
    "def generate_word_search(n, words, horizontal = True, vertical = False, reversed = False):\n",
    "    elements = [chr(random.randint(ord(\"A\"),ord(\"Z\"))) for i in range(n*n)]\n",
    "    array = np.array(elements).reshape(n,n)\n",
    "    for word in words:\n",
    "        assert len(word) <= n, \"{0} is larger than the grid\".format(word)\n",
    "            \n",
    "        for elt in word:\n",
    "            assert elt.isalpha(), \"{0} contains non-letter characters\".format(word)\n",
    "            \n",
    "        if reversed == True:\n",
    "            reverse = random.choice([\"reversed\",\"not_reversed\"])\n",
    "            if reverse == \"reversed\":\n",
    "                word = word[::-1]\n",
    "                \n",
    "        if horizontal == False and vertical == False:\n",
    "            assert horizontal != False and vertical != False, \"At least one of the directions have to be True\" \n",
    "        \n",
    "        if horizontal == True and vertical == True:\n",
    "            direction = random.choice([\"horizontal\",\"vertical\"])\n",
    "            if direction == \"horizontal\":\n",
    "                generate_words_on_row(array,word)\n",
    "            else:\n",
    "                generate_words_on_column(array,word)\n",
    "        elif horizontal == True and vertical == False:\n",
    "            generate_words_on_row(array,word)\n",
    "        elif horizontal == False and vertical == True:\n",
    "            generate_words_on_column(array,word)\n",
    "\n",
    "    return \"\\n\".join(\" \".join(elt for elt in row) for row in array)\n",
    "    \n",
    "def generate_words_on_row(array, word):\n",
    "    word = word.upper()\n",
    "    random_row = random.choice(array)\n",
    "    random_row_index = random.randint(0,len(random_row)-1)\n",
    "\n",
    "    while len(random_row) - random_row_index < len(word):\n",
    "        random_row = random.choice(array)\n",
    "        random_row_index = random.randint(0,len(random_row)-1)\n",
    "\n",
    "    for i in range(random_row_index, random_row_index + len(word)):\n",
    "        random_row[i] = word[i - random_row_index]\n",
    "        \n",
    "    return array\n",
    "\n",
    "def generate_words_on_column(array, word):\n",
    "    word = word.upper()\n",
    "    random_column = array[:,random.randint(0,array.shape[1]-1)]\n",
    "    random_column_index = random.randint(0,len(random_column)-1)\n",
    "\n",
    "    while len(random_column) - random_column_index < len(word):\n",
    "        random_column = array[:,random.randint(0,array.shape[1]-1)]\n",
    "        random_column_index = random.randint(0,len(random_column)-1)\n",
    "\n",
    "    for i in range(random_column_index, random_column_index + len(word)):\n",
    "        random_column[i] = word[i - random_column_index]\n",
    "        \n",
    "    return array        \n",
    "    \n",
    "print(generate_word_search(6, [\"quizzz\", \"lambda\", \"matrix\", \"spleen\", \"basil\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T12:17:13.295274Z",
     "start_time": "2020-11-26T12:17:13.290394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S P L E E N N N\n",
      "M D H E H C B L\n",
      "O L D F F G W M\n",
      "O Z C D J R Z G\n",
      "L A M A T R I X\n",
      "Z M I Y Z F F P\n",
      "B A S I L O P U\n",
      "K C O G S D X O\n",
      "\n",
      "Y X G U L Z F Q\n",
      "I X K A A R B M\n",
      "Q A C P M T A Y\n",
      "D V O I B E S E\n",
      "R D D C D J I X\n",
      "O U I E A J L V\n",
      "H O N L C Z E H\n",
      "G Y G Q H U N B\n",
      "\n",
      "Z L A M B D A L\n",
      "V L J X V B Z B\n",
      "V O S P L E E N\n",
      "Z S D H L N L Y\n",
      "X C O D I N G U\n",
      "J M A T R I X C\n",
      "E O F G X Q F I\n",
      "X I W B A S I L\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_word_search(8, [\"coding\", \"lambda\", \"matrix\", \"spleen\", \"basil\"]))\n",
    "print()\n",
    "print(generate_word_search(8, [\"coding\", \"lambda\", \"matrix\", \"spleen\", \"basil\"], horizontal=False, vertical=True))\n",
    "print()\n",
    "print(generate_word_search(8, [\"coding\", \"lambda\", \"matrix\", \"spleen\", \"basil\"],  vertical=True))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T13:28:38.179151Z",
     "start_time": "2020-11-27T13:28:38.174271Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A B X B\n",
      "P R A M\n",
      "N I M O\n",
      "B E T A\n"
     ]
    }
   ],
   "source": [
    "print(generate_word_search(4, [\"beta\", \"pram\", \"nimo\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:50:11.424470Z",
     "start_time": "2020-11-28T10:50:11.411783Z"
    }
   },
   "outputs": [],
   "source": [
    "## Tests\n",
    "\n",
    "def fails(expr):\n",
    "    try:\n",
    "        expr()\n",
    "    except:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def n_lines(s):\n",
    "    return len(s.splitlines())\n",
    "\n",
    "def elt_check(s, n):    \n",
    "    return all(len(line.split())==n for line in s.splitlines())\n",
    "\n",
    "assert n_lines(generate_word_search(8, [\"matrix\", \"spleen\", \"basil\"]))==8\n",
    "assert n_lines(generate_word_search(6, [\"matrix\", \"spleen\", \"basil\"]))==6\n",
    "assert n_lines(generate_word_search(12, [\"matrix\", \"spleen\", \"basil\"]))==12\n",
    "\n",
    "assert elt_check(generate_word_search(12, [\"matrix\", \"spleen\", \"basil\"]), 12)\n",
    "assert elt_check(generate_word_search(8, [\"matrix\", \"spleen\", \"basil\"]), 8)\n",
    "assert elt_check(generate_word_search(6, [\"matrix\", \"spleen\", \"basil\"]), 6)\n",
    "assert elt_check(generate_word_search(3, [\"tea\", \"bee\", \"elk\"]), 3)\n",
    "assert n_lines(generate_word_search(3, [\"tea\", \"bee\", \"elk\"])) ==  3\n",
    "assert n_lines(generate_word_search(6, []))==6\n",
    "assert elt_check(generate_word_search(6, []),6)\n",
    "\n",
    "\n",
    "assert (lambda :generate_word_search(8, [\"127\", \"9\", \"matrix\", \"spleen\", \"basil\"]))\n",
    "\n",
    "assert fails(lambda :generate_word_search(4, [\"coding\", \"lambda\", \"matrix\", \"spleen\", \"basil\"])) and not fails(lambda:generate_word_search(4, [\"code\", \"lamb\", \"matt\"]))\n",
    "assert fails(lambda :generate_word_search(8, [\"127\", \"9\", \"matrix\", \"spleen\", \"basil\"]))\n",
    "assert fails(lambda :generate_word_search(8, [\"back{}\", \"span's\", \"matrix\", \"spleen\", \"'''\"]))\n",
    "assert fails(lambda :generate_word_search(8, [\"coding\", \"lambda\", \"matrix\", \"spleen\", \"basil\"], horizontal=False)) and not fails(lambda :generate_word_search(8, [\"coding\", \"lambda\", \"matrix\", \"spleen\", \"basil\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# END OF EXAM\n",
    "\n",
    "Please:\n",
    "\n",
    "* Take a break.\n",
    "* Make sure you read each question carefully. The number one reason to lose marks is to not read the question!\n",
    "* Check that each of your cells run as you expect. Try `Kernel/Restart and Run All` to make sure.\n",
    "* Submit your solution on Moodle \n",
    "* And then relax :) \n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
